{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62091e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "import cv2\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "SERVICES = {\n",
    "    'asr': 'http://127.0.0.1:8001',\n",
    "    'diarization': 'http://127.0.0.1:8002',\n",
    "    'emotion': 'http://127.0.0.1:8003',\n",
    "    'nlp': 'http://127.0.0.1:8004',\n",
    "    'nonverb': 'http://127.0.0.1:8005',\n",
    "    'robot_data': 'http://127.0.0.1:8006',\n",
    "    'robot_speed': 'http://127.0.0.1:8007'\n",
    "}\n",
    "\n",
    "# CONFIGURATION \n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(\n",
    "    cv2.aruco.DICT_5X5_100\n",
    ")  # change for appropriate ArUco code\n",
    "ARUCO_PARAMS = cv2.aruco.DetectorParameters()\n",
    "ARUCO_DETECTOR = cv2.aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMS)\n",
    "MARKER_ID = None\n",
    "PIXELS_PER_CM = 4.0   # adjust when camera calibration is known\n",
    "SMOOTH_WINDOW = 9\n",
    "\n",
    "def compute_robot_winning_rate(video_path: str, window_start: float, window_end: float) -> dict:\n",
    "    \"\"\"\n",
    "    Call the robot speed service to compute a winning rate\n",
    "    for the given time window in the video.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"video_path\": video_path,\n",
    "        \"window_start\": window_start,\n",
    "        \"window_end\": window_end,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"{SERVICES['robot_speed']}/winning_rate\",\n",
    "        json=payload,\n",
    "        timeout=60,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def compute_speed_for_window(video_path: str, window_start: float, window_end: float):\n",
    "    \"\"\"\n",
    "    Process only the specified time window of the video and\n",
    "    return average speed (cm/s) and number of detections.\n",
    "    \"\"\"\n",
    "    if window_end <= window_start:\n",
    "        raise ValueError(\"window_end must be greater than window_start\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "    # Seek to window start (in milliseconds)\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, window_start * 1000.0)\n",
    "    \n",
    "    positions = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Current timestamp in seconds\n",
    "        t = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "\n",
    "        # Stop once we are past the window\n",
    "        if t >= window_end:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = ARUCO_DETECTOR.detectMarkers(gray)\n",
    "\n",
    "        if ids is not None:\n",
    "            for i, marker_id in enumerate(ids.flatten()):\n",
    "                if MARKER_ID is None or marker_id == MARKER_ID:\n",
    "                    c = corners[i][0]\n",
    "                    center = np.mean(c, axis=0)\n",
    "                    x, y = center\n",
    "                    positions.append((t, x, y))\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(positions) <= 1:\n",
    "        # Not enough detections in this window to compute speed\n",
    "        return np.nan, 0\n",
    "\n",
    "    positions = np.array(positions, dtype=float)\n",
    "    t, x, y = positions[:, 0], positions[:, 1], positions[:, 2]\n",
    "\n",
    "    # Smooth positions for stability\n",
    "    if len(x) >= SMOOTH_WINDOW:\n",
    "        x = savgol_filter(x, SMOOTH_WINDOW, 3)\n",
    "        y = savgol_filter(y, SMOOTH_WINDOW, 3)\n",
    "\n",
    "    # Calculate instantaneous speeds\n",
    "    dt = np.diff(t)\n",
    "    dx, dy = np.diff(x), np.diff(y)\n",
    "    dt[dt == 0] = np.finfo(float).eps  # avoid division by zero\n",
    "\n",
    "    distance = np.sqrt(dx**2 + dy**2)  # pixel distance\n",
    "    speed_pixels = distance / dt  # pixels per second\n",
    "    \n",
    "    # Convert to cm/s\n",
    "    speed_cm_s = speed_pixels / PIXELS_PER_CM\n",
    "\n",
    "    avg_speed_cm_s = float(np.mean(speed_cm_s))\n",
    "    num_detections = len(t)\n",
    "\n",
    "    return avg_speed_cm_s, num_detections\n",
    "\n",
    "def test_marker_detection(video_path: str, start_time: float = 0.0, num_frames: int = 10):\n",
    "    \"\"\"Test marker detection and display results.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000.0)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = ARUCO_DETECTOR.detectMarkers(gray)\n",
    "        \n",
    "        # Draw detected markers\n",
    "        if ids is not None:\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "            print(f\"Frame {i}: Detected markers {ids.flatten()}\")\n",
    "        else:\n",
    "            print(f\"Frame {i}: No markers detected\")\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691db59f",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: http://127.0.0.1:8007/winning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m audio_name = os.listdir(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Audio/processed\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m video_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Videos/top_cam/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_name.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.MP4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mcompute_robot_winning_rate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_end\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60.0\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRobot Winning Rate:\u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcompute_robot_winning_rate\u001b[39m\u001b[34m(video_path, window_start, window_end)\u001b[39m\n\u001b[32m     24\u001b[39m payload = {\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvideo_path\u001b[39m\u001b[33m\"\u001b[39m: video_path,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwindow_start\u001b[39m\u001b[33m\"\u001b[39m: window_start,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwindow_end\u001b[39m\u001b[33m\"\u001b[39m: window_end,\n\u001b[32m     28\u001b[39m }\n\u001b[32m     29\u001b[39m response = requests.post(\n\u001b[32m     30\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSERVICES[\u001b[33m'\u001b[39m\u001b[33mrobot_speed\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/winning_rate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m     json=payload,\n\u001b[32m     32\u001b[39m     timeout=\u001b[32m60\u001b[39m,\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pipeline_08/.venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8007/winning_rate"
     ]
    }
   ],
   "source": [
    "dir = \"/home/UMRobotics/Desktop/edmo_dataset/07102025_school_id_1/20251007_100704/Sessions/20251007/Suzanne/101120\"\n",
    "audio_name = os.listdir(f\"{dir}/Audio/processed\")[0]\n",
    "video_path = f\"{dir}/Videos/top_cam/{audio_name.split('.')[0]}.MP4\"\n",
    "\n",
    "response = compute_robot_winning_rate(\n",
    "    video_path=video_path,\n",
    "    window_start=120.0,\n",
    "    window_end=180.0\n",
    ")\n",
    "print(\"Robot Winning Rate:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ad2af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_speed_for_window(\n",
    "    video_path=video_path,\n",
    "    window_start=720.0,\n",
    "    window_end=750.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8455abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/UMRobotics/Desktop/edmo_dataset/07102025_school_id_1/20251007_100704/Sessions/20251007/Suzanne/101120/Videos/top_cam/GX010576.MP4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fc2f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: No markers detected\n",
      "Frame 1: No markers detected\n",
      "Frame 2: No markers detected\n",
      "Frame 3: No markers detected\n",
      "Frame 4: No markers detected\n",
      "Frame 5: No markers detected\n",
      "Frame 6: No markers detected\n",
      "Frame 7: No markers detected\n",
      "Frame 8: No markers detected\n",
      "Frame 9: No markers detected\n",
      "Frame 10: No markers detected\n",
      "Frame 11: No markers detected\n",
      "Frame 12: No markers detected\n",
      "Frame 13: No markers detected\n",
      "Frame 14: No markers detected\n",
      "Frame 15: No markers detected\n",
      "Frame 16: No markers detected\n",
      "Frame 17: No markers detected\n",
      "Frame 18: No markers detected\n",
      "Frame 19: No markers detected\n",
      "Frame 20: No markers detected\n",
      "Frame 21: No markers detected\n",
      "Frame 22: No markers detected\n",
      "Frame 23: No markers detected\n",
      "Frame 24: No markers detected\n",
      "Frame 25: No markers detected\n",
      "Frame 26: No markers detected\n",
      "Frame 27: No markers detected\n",
      "Frame 28: No markers detected\n",
      "Frame 29: No markers detected\n"
     ]
    }
   ],
   "source": [
    "test_marker_detection(video_path, start_time=720.0, num_frames=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
